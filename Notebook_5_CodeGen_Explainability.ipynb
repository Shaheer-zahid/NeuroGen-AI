{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfTX6NmO3Grn",
        "outputId": "cfab4350-d561-406c-95cb-5a3fbcb4ded6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependencies installed successfully.\n",
            "Dependencies installed successfully.\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-community langchain-google-genai google-generativeai shap pandas numpy scikit-learn matplotlib -q\n",
        "print(\"Dependencies installed successfully.\")\n",
        "\n",
        "!pip install transformers torch -q\n",
        "print(\"Dependencies installed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DafHs4dlLIGj",
        "outputId": "557fa268-7953-4d0d-845c-d6aba37aecfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    logger.info(\"Google Drive mounted successfully.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to mount Google Drive: {str(e)}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1CICkaJLO9o",
        "outputId": "598893a4-65cb-4210-94ef-2cb88856494e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " coordinator_logs.txt\n",
            " Data_Analysis_Quality_Preprocessing.ipynb\n",
            " data_analysis_report.json\n",
            " dataset_data.json\n",
            " deploy\n",
            " explainability_output\n",
            " explainability_outputs\n",
            "'fine_tuned_traditional_ml_(random_forest-like).joblib'\n",
            " hyperparams.json\n",
            " Notebook_5_CodeGen_Explainability.ipynb\n",
            " Part_1_Environment_Setup.ipynb\n",
            " Part_3_Model_Training_and_Evaluation.ipynb\n",
            " part3_output.json\n",
            " part4_output.json\n",
            " preprocessed_data.pt\n",
            " processed_dataset.csv\n",
            " quality_check_report.json\n",
            " selected_config_checkpoint.pkl\n",
            " Sentiment_Analysis_Model_Optimization.ipynb\n",
            " trained_traditional_ml_random_forest-like_encoder.joblib\n",
            " trained_traditional_ml_random_forest-like.joblib\n",
            " trained_traditional_ml_random_forest-like_vectorizer.joblib\n",
            "'train_traditional_ml_(random_forest-like).py'\n",
            " train_traditional_ml_random_forest-like.py\n",
            " user_dataset_prompt.json\n",
            " user_feedback.csv\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/drive/MyDrive/Sentiment_Project\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-80EyNGzZk9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "import pandas as pd\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Define global paths\n",
        "project_dir = \"/content/drive/MyDrive/Sentiment_Project\"\n",
        "dataset_path = os.path.join(project_dir, \"processed_dataset.csv\")\n",
        "output_dir = os.path.join(project_dir, \"explainability_outputs\")\n",
        "model_path = os.path.join(project_dir, f\"fine_tuned_{selected_config['model'].replace(' ', '_').lower()}.pt\" if 'selected_config' in globals() and 'model' in selected_config else os.path.join(project_dir, \"fine_tuned_model.pt\"))\n",
        "checkpoint_path = os.path.join(project_dir, \"selected_config_checkpoint.pkl\")\n",
        "\n",
        "# Retrieve selected_config (must be set by PPO optimization in Notebook 3, Cell 7)\n",
        "try:\n",
        "    if 'selected_config' not in globals():\n",
        "        import pickle\n",
        "        if os.path.exists(checkpoint_path):\n",
        "            with open(checkpoint_path, 'rb') as f:\n",
        "                selected_config = pickle.load(f)\n",
        "            logger.info(f\"Loaded selected_config from checkpoint: {selected_config}\")\n",
        "            model_path = os.path.join(project_dir, f\"fine_tuned_{selected_config['model'].replace(' ', '_').lower()}.pt\")\n",
        "        else:\n",
        "            logger.error(\"selected_config not found in globals and checkpoint not available. Run Notebook 3, Cell 7 to set PPO-optimized configuration.\")\n",
        "            raise ValueError(\"selected_config must be defined by PPO optimization in Notebook 3, Cell 7.\")\n",
        "    else:\n",
        "        logger.info(f\"Retrieved selected_config from globals: {selected_config}\")\n",
        "        model_path = os.path.join(project_dir, f\"fine_tuned_{selected_config['model'].replace(' ', '_').lower()}.pt\")\n",
        "\n",
        "    # Validate selected_config\n",
        "    required_keys = ['approach', 'model']\n",
        "    for key in required_keys:\n",
        "        if key not in selected_config:\n",
        "            logger.error(f\"selected_config missing required key: '{key}'. Current selected_config: {selected_config}\")\n",
        "            raise ValueError(f\"selected_config must contain '{key}' key.\")\n",
        "    if 'hyperparams' not in selected_config:\n",
        "        selected_config['hyperparams'] = {}  # Default to empty dict if not present\n",
        "        logger.info(\"Added empty 'hyperparams' to selected_config as it was missing.\")\n",
        "\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to retrieve selected_config: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "logger.info(\"Setup completed. Global paths and selected_config retrieved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVITdf7uP5t7"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain langchain-community langchain-google-genai google-generativeai pandas numpy scikit-learn matplotlib shap -q\n",
        "logger.info(\"Installed compatible versions of langchain, langchain-community, langchain-google-genai, google-generativeai, pandas, numpy, scikit-learn, matplotlib, and shap.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "4b57nnxNLRCS",
        "outputId": "c4e68b0d-2da7-4180-fea7-7b62e9cfa01c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d3bfaa5b358f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;31m# Prompt user for input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0muser_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please enter your prompt for generating the Python script (e.g., 'Add 5-fold cross-validation and save logs to a file'): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muser_prompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0muser_prompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"..\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"do it\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User prompt must be meaningful and not just dots, spaces, or vague phrases like 'do it'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# Cell 3b: Code Generator Agent\n",
        "# Purpose: Generate a tailored Python script based on user prompt and dynamically selected operations using LangChain and Gemini.\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableSequence\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "import os\n",
        "import re\n",
        "import google.generativeai as genai\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "import logging\n",
        "import json\n",
        "import subprocess\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(filename='code_generator.log', level=logging.INFO,\n",
        "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Configure Gemini API key (set by default)\n",
        "api_key = \"AIzaSyDH9NNbWsRODKSsaQWyvCucS3rx-4zYiEI\"\n",
        "genai.configure(api_key=api_key)\n",
        "logger.info(\"Gemini API key configured successfully.\")\n",
        "\n",
        "# List available models and select the appropriate one\n",
        "try:\n",
        "    available_models = [model.name for model in genai.list_models() if 'generateContent' in model.supported_generation_methods]\n",
        "    logger.info(f\"Available Gemini models: {available_models}\")\n",
        "    selected_model = \"models/gemini-1.5-flash-001\"\n",
        "    if selected_model not in available_models:\n",
        "        raise ValueError(f\"Selected model {selected_model} not found in available models: {available_models}\")\n",
        "    logger.info(f\"Selected Gemini model: {selected_model}\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to list Gemini models: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "# Initialize Gemini model with increased flexibility\n",
        "try:\n",
        "    gemini_llm = GoogleGenerativeAI(\n",
        "        model=selected_model,\n",
        "        google_api_key=api_key,\n",
        "        temperature=0.5,\n",
        "        max_output_tokens=2000,\n",
        "        max_retries=3\n",
        "    )\n",
        "    logger.info(\"Gemini model initialized successfully.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to initialize Gemini model: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "# Function to merge user prompt with dynamic prompt\n",
        "def create_combined_prompt(user_prompt, model, approach, hyperparams, dataset_path, output_path):\n",
        "    \"\"\"Merge user prompt with a dynamic template to generate a tailored Python script.\"\"\"\n",
        "    if not isinstance(hyperparams, dict) or not hyperparams:\n",
        "        raise ValueError(\"Hyperparameters must be a non-empty dictionary.\")\n",
        "    dynamic_template = \"\"\"\n",
        "    Use the dataset from {dataset_path} (a CSV with 'review' and 'sentiment' columns containing string labels 'negative' and 'positive').\n",
        "    Preprocess the 'sentiment' column by encoding string labels ('negative' and 'positive') to integers (e.g., 0 and 1) using sklearn.preprocessing.LabelEncoder.\n",
        "    Generate a complete Python script to train a {model} model using the {approach} approach with hyperparameters provided dynamically via command-line arguments (e.g., argparse).\n",
        "    The script must accept command-line arguments: --data_path, --hyperparameters_path, --model_path, --vectorizer_path, and --encoder_path.\n",
        "    If arguments are not provided, use defaults: --data_path={dataset_path}, --hyperparameters_path=/content/drive/MyDrive/Sentiment_Project/hyperparams.json,\n",
        "    --model_path={output_path}, --vectorizer_path={vectorizer_path}, --encoder_path={encoder_path}.\n",
        "    The script must log the dataset shape and label distribution for validation.\n",
        "    Include evaluation metrics (accuracy, F1 score) with logging using the logging module for both training and test sets, ensuring pos_label is set to the integer encoded value for 'positive' (e.g., 1).\n",
        "    Save the trained model to the path specified by --model_path using joblib.dump.\n",
        "    Save the TfidfVectorizer to the path specified by --vectorizer_path using joblib.dump.\n",
        "    Save the LabelEncoder to the path specified by --encoder_path using joblib.dump.\n",
        "    Use functions for modularity and follow Python best practices with detailed comments.\n",
        "    Strictly use the hyperparameters n_estimators=300, max_depth=10, and min_samples_split=10 from the provided --hyperparameters_path or default values, and do not use any other values.\n",
        "    Return only the Python script code, starting with 'import', 'def', '#', or 'class', without any Markdown formatting (e.g., no ```python wrappers).\n",
        "    Ensure the script is complete and functional, avoiding truncation or partial code.\n",
        "    \"\"\"\n",
        "    base_prompt = PromptTemplate(\n",
        "        input_variables=[\"model\", \"approach\", \"hyperparams\", \"dataset_path\", \"output_path\", \"vectorizer_path\", \"encoder_path\"],\n",
        "        template=dynamic_template\n",
        "    ).format(\n",
        "        model=model,\n",
        "        approach=approach,\n",
        "        hyperparams=str(hyperparams),\n",
        "        dataset_path=dataset_path,\n",
        "        output_path=output_path,\n",
        "        vectorizer_path=output_path.replace('.joblib', '_vectorizer.joblib'),\n",
        "        encoder_path=output_path.replace('.joblib', '_encoder.joblib')\n",
        "    )\n",
        "    combined_prompt = f\"Generate a complete, professional Python script to train a {model} model using the {approach} approach. {user_prompt}\\n{base_prompt}\"\n",
        "    return combined_prompt\n",
        "\n",
        "# Function to generate code using Gemini with custom config\n",
        "def gemini_generate_code(prompt, gemini_llm):\n",
        "    \"\"\"Generate Python code using the Gemini model with enhanced error handling.\"\"\"\n",
        "    try:\n",
        "        config = RunnableConfig(max_retries=3)\n",
        "        response = gemini_llm.invoke(prompt, config=config)\n",
        "        response_text = response.content if hasattr(response, 'content') else str(response)\n",
        "        if isinstance(response_text, list):\n",
        "            response_text = \" \".join(response_text)\n",
        "        # Remove Markdown formatting and handle incomplete lines\n",
        "        if response_text.startswith(\"```python\") and response_text.endswith(\"```\"):\n",
        "            response_text = response_text.replace(\"```python\\n\", \"\").replace(\"\\n```\", \"\").strip()\n",
        "        elif response_text.startswith(\"```\") and response_text.endswith(\"```\"):\n",
        "            response_text = response_text.replace(\"```\", \"\").strip()\n",
        "        # Remove any trailing incomplete lines\n",
        "        response_text = \"\\n\".join(line for line in response_text.split(\"\\n\") if line.strip())\n",
        "        response_text = re.sub(r'\\n\\s*\\n+', '\\n', response_text).strip()\n",
        "        logger.info(f\"Raw generated code:\\n{response_text}\")\n",
        "        if not response_text or not any(response_text.strip().startswith(prefix) for prefix in ('import', 'def', '#', 'class')):\n",
        "            logger.warning(f\"Invalid or empty Python code detected. Raw output: {response_text}\")\n",
        "            raise ValueError(\"Generated output does not appear to be valid Python code. Check logs for details.\")\n",
        "        return response_text\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to generate code with Gemini: {str(e)}\")\n",
        "        if \"ResourceExhausted\" in str(e):\n",
        "            logger.warning(\"Quota exceeded. Please wait for reset or check https://aistudio.google.com/ for details.\")\n",
        "        raise\n",
        "\n",
        "# Create RunnableSequence\n",
        "try:\n",
        "    code_chain = RunnableSequence(\n",
        "        lambda x: create_combined_prompt(x.get(\"user_prompt\", \"\"), x[\"model\"], x[\"approach\"], x[\"hyperparams\"], x[\"dataset_path\"], x[\"output_path\"]),\n",
        "        lambda x: gemini_generate_code(x, gemini_llm)\n",
        "    )\n",
        "    logger.info(\"RunnableSequence created successfully.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to create RunnableSequence: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "# Prompt user for input\n",
        "try:\n",
        "    user_prompt = input(\"Please enter your prompt for generating the Python script (e.g., 'Add 5-fold cross-validation and save logs to a file'): \")\n",
        "    if not user_prompt.strip() or user_prompt.strip() in [\"..\", \".\", \" \", \"do it\"]:\n",
        "        raise ValueError(\"User prompt must be meaningful and not just dots, spaces, or vague phrases like 'do it'.\")\n",
        "    logger.info(f\"User provided prompt: {user_prompt}\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to get user prompt: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "# Prepare context dynamically from selected_config\n",
        "try:\n",
        "    # Load selected_config from part4output.json\n",
        "    with open(\"/content/drive/MyDrive/Sentiment_Project/part4_output.json\", \"r\") as f:\n",
        "        selected_config = json.load(f)[\"selected_config\"]\n",
        "\n",
        "    model = selected_config.get(\"model\", \"Traditional ML (Random Forest-like)\")\n",
        "    approach = selected_config.get(\"approach\", \"Traditional ML\")\n",
        "    hyperparams = selected_config.get(\"hyperparams\", {\"n_estimators\": 300, \"max_depth\": 10, \"min_samples_split\": 10})\n",
        "\n",
        "    if not all([model, approach, hyperparams]):\n",
        "        missing = [k for k, v in {\"model\": model, \"approach\": approach, \"hyperparams\": hyperparams}.items() if not v]\n",
        "        raise ValueError(f\"Missing required configuration parameters: {missing}\")\n",
        "\n",
        "    dataset_path = \"/content/drive/MyDrive/Sentiment_Project/processed_dataset.csv\"\n",
        "    output_path = os.path.join(\"/content/drive/MyDrive/Sentiment_Project\", f\"trained_{model.replace(' ', '_').lower().replace('(', '').replace(')', '')}.joblib\")\n",
        "\n",
        "    if not os.path.exists(dataset_path):\n",
        "        raise FileNotFoundError(f\"Dataset not found at {dataset_path}\")\n",
        "\n",
        "    # Save hyperparameters to a JSON file for the script to use\n",
        "    hyperparams_path = os.path.join(\"/content/drive/MyDrive/Sentiment_Project\", \"hyperparams.json\")\n",
        "    with open(hyperparams_path, \"w\") as f:\n",
        "        json.dump(hyperparams, f)\n",
        "    logger.info(f\"Hyperparameters saved to {hyperparams_path}\")\n",
        "\n",
        "    response = code_chain.invoke({\n",
        "        \"user_prompt\": user_prompt,\n",
        "        \"model\": model,\n",
        "        \"approach\": approach,\n",
        "        \"hyperparams\": hyperparams,\n",
        "        \"dataset_path\": dataset_path,\n",
        "        \"output_path\": output_path\n",
        "    })\n",
        "\n",
        "    script_path = os.path.join(\"/content/drive/MyDrive/Sentiment_Project\", f\"train_{model.replace(' ', '_').lower().replace('(', '').replace(')', '')}.py\")\n",
        "    with open(script_path, \"w\") as f:\n",
        "        f.write(response)\n",
        "    logger.info(f\"Generated training script saved to {script_path}\")\n",
        "\n",
        "    # Execute the generated script as a subprocess with arguments\n",
        "    try:\n",
        "        logger.info(f\"Running the generated script: {script_path}\")\n",
        "        cmd = [\n",
        "            \"python\",\n",
        "            script_path,\n",
        "            f\"--data_path={dataset_path}\",\n",
        "            f\"--hyperparameters_path={hyperparams_path}\",\n",
        "            f\"--model_path={output_path}\",\n",
        "            f\"--vectorizer_path={output_path.replace('.joblib', '_vectorizer.joblib')}\",\n",
        "            f\"--encoder_path={output_path.replace('.joblib', '_encoder.joblib')}\"\n",
        "        ]\n",
        "        process = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
        "        logger.info(f\"Script output: {process.stdout}\")\n",
        "        if process.stderr:\n",
        "            logger.error(f\"Script errors: {process.stderr}\")\n",
        "        # Verify model file creation\n",
        "        if os.path.exists(output_path):\n",
        "            logger.info(f\"Model successfully saved to {output_path}\")\n",
        "        else:\n",
        "            logger.error(f\"Model file not found at {output_path} after execution.\")\n",
        "            raise FileNotFoundError(f\"Model file not created at {output_path}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        logger.error(f\"Error executing the script: {e.stderr}\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error executing the script: {str(e)}\")\n",
        "        raise\n",
        "except Exception as e:\n",
        "    logger.error(f\"Error generating or running training script: {str(e)}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "susdIHDaMIDB"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Custom Transformer for SHAP\n",
        "# Purpose: Define a custom transformer to preprocess text data for SHAP compatibility.\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "import logging\n",
        "\n",
        "# Configure logging if not already done\n",
        "if not logging.getLogger().handlers:\n",
        "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class CustomTextTransformer:\n",
        "    def __init__(self, tokenizer_name=\"bert-base-uncased\", max_length=128):\n",
        "        \"\"\"Initialize the transformer with a tokenizer and max length.\n",
        "        Args:\n",
        "            tokenizer_name (str): Name of the pre-trained tokenizer (default: \"bert-base-uncased\").\n",
        "            max_length (int): Maximum sequence length for tokenization.\n",
        "        \"\"\"\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "        self.max_length = max_length\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    def fit(self, texts, labels):\n",
        "        \"\"\"Fit the transformer by encoding labels.\n",
        "        Args:\n",
        "            texts (list): List of text samples.\n",
        "            labels (list): List of corresponding labels.\n",
        "        Returns:\n",
        "            self: The fitted transformer.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.label_encoder.fit(labels)\n",
        "            logger.info(\"Label encoder fitted successfully with classes: %s\", self.label_encoder.classes_)\n",
        "            return self\n",
        "        except Exception as e:\n",
        "            logger.error(\"Error fitting label encoder: %s\", str(e))\n",
        "            raise\n",
        "\n",
        "    def transform(self, texts):\n",
        "        \"\"\"Transform texts into input_ids and attention_mask for the model.\n",
        "        Args:\n",
        "            texts (list): List of text samples.\n",
        "        Returns:\n",
        "            tuple: (input_ids, attention_mask) as PyTorch tensors.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            encodings = self.tokenizer(\n",
        "                texts,\n",
        "                truncation=True,\n",
        "                padding=True,\n",
        "                max_length=self.max_length,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "            return encodings['input_ids'], encodings['attention_mask']\n",
        "        except Exception as e:\n",
        "            logger.error(\"Error transforming texts: %s\", str(e))\n",
        "            raise\n",
        "\n",
        "    def fit_transform(self, texts, labels):\n",
        "        \"\"\"Fit and transform in one step.\n",
        "        Args:\n",
        "            texts (list): List of text samples.\n",
        "            labels (list): List of corresponding labels.\n",
        "        Returns:\n",
        "            tuple: (input_ids, attention_mask) as PyTorch tensors.\n",
        "        \"\"\"\n",
        "        self.fit(texts, labels)\n",
        "        return self.transform(texts)\n",
        "\n",
        "    def inverse_transform(self, encoded_labels):\n",
        "        \"\"\"Inverse transform encoded labels back to original labels.\n",
        "        Args:\n",
        "            encoded_labels (array-like): Encoded label indices.\n",
        "        Returns:\n",
        "            list: Original labels.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return self.label_encoder.inverse_transform(encoded_labels)\n",
        "        except Exception as e:\n",
        "            logger.error(\"Error inverse transforming labels: %s\", str(e))\n",
        "            raise\n",
        "\n",
        "logger.info(\"CustomTextTransformer class defined successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2SdFWT2MIQb",
        "outputId": "edbf3c1f-c82d-454e-a3c9-5ba5f0f6cca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Top 20 TF-IDF Features:\n",
            "        feature     score\n",
            "96           br  0.158836\n",
            "575       movie  0.081215\n",
            "323        film  0.071504\n",
            "502        like  0.039808\n",
            "461        just  0.036872\n",
            "374        good  0.034723\n",
            "832       story  0.029514\n",
            "881        time  0.029505\n",
            "695      really  0.029123\n",
            "62          bad  0.026889\n",
            "378       great  0.026559\n",
            "628      people  0.024301\n",
            "235         don  0.024018\n",
            "576      movies  0.023748\n",
            "951       watch  0.022078\n",
            "530        make  0.021380\n",
            "876       think  0.020980\n",
            "955         way  0.020966\n",
            "755        seen  0.020959\n",
            "132  characters  0.020842\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: TF-IDF Top Features Analysis\n",
        "# Purpose: Extract, display, and visualize the top TF-IDF features (words) from the dataset to understand key terms influencing sentiment.\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from google.colab import drive\n",
        "\n",
        "# Configure logging\n",
        "if not logging.getLogger().handlers:\n",
        "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def extract_top_tfidf_features(dataset_path, output_dir, top_n=20):\n",
        "    \"\"\"Extract, visualize, and save the top TF-IDF features from the dataset.\n",
        "    Args:\n",
        "        dataset_path (str): Path to the dataset CSV file.\n",
        "        output_dir (str): Directory to save output files.\n",
        "        top_n (int): Number of top features to display (default: 20).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Mount Google Drive\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "        # Create output directory if it doesn't exist\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Load dataset\n",
        "        df = pd.read_csv(dataset_path)\n",
        "        texts = df['review'].tolist()\n",
        "        logger.info(f\"Loaded dataset with {len(texts)} samples.\")\n",
        "\n",
        "        # Apply TF-IDF vectorization\n",
        "        vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "        tfidf_matrix = vectorizer.fit_transform(texts)\n",
        "        feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "        # Calculate average TF-IDF scores across all documents\n",
        "        tfidf_scores = tfidf_matrix.mean(axis=0).A1  # Convert to 1D array\n",
        "        tfidf_df = pd.DataFrame({'feature': feature_names, 'score': tfidf_scores})\n",
        "        top_features = tfidf_df.sort_values(by='score', ascending=False).head(top_n)\n",
        "\n",
        "        # Log and display top features\n",
        "        logger.info(f\"Top {top_n} TF-IDF features:\\n{top_features}\")\n",
        "        print(f\"Top {top_n} TF-IDF Features:\")\n",
        "        print(top_features)\n",
        "\n",
        "        # Save top features to a CSV file\n",
        "        csv_path = os.path.join(output_dir, \"top_tfidf_features.csv\")\n",
        "        top_features.to_csv(csv_path, index=False)\n",
        "        logger.info(f\"Top TF-IDF features saved to {csv_path}\")\n",
        "\n",
        "        # Create a bar graph of the top TF-IDF features\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.barh(top_features['feature'], top_features['score'], color='skyblue')\n",
        "        plt.xlabel('Average TF-IDF Score')\n",
        "        plt.ylabel('Feature (Word)')\n",
        "        plt.title(f'Top {top_n} TF-IDF Features for Sentiment Analysis')\n",
        "        plt.gca().invert_yaxis()  # Invert y-axis to show highest scores at the top\n",
        "\n",
        "        # Save the graph as a PNG file\n",
        "        graph_path = os.path.join(output_dir, \"top_tfidf_features_graph.png\")\n",
        "        plt.savefig(graph_path, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        logger.info(f\"TF-IDF features graph saved to {graph_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during TF-IDF feature extraction or visualization: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Run TF-IDF feature extraction and visualization\n",
        "try:\n",
        "    extract_top_tfidf_features(\n",
        "        dataset_path=\"/content/drive/MyDrive/Sentiment_Project/processed_dataset.csv\",\n",
        "        output_dir=\"/content/drive/MyDrive/Sentiment_Project/explainability_outputs\",\n",
        "        top_n=20\n",
        "    )\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to extract or visualize top TF-IDF features: {str(e)}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "model = joblib.load(\"/content/drive/MyDrive/Sentiment_Project/trained_traditional_ml_random_forest-like.joblib\")\n",
        "print(\"Model loaded successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdVvAYhi67q2",
        "outputId": "665fbde9-d265-4c3c-8494-69c6b47d8553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb8wyWPn278d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c797e7b8-3bdf-4159-a9fe-358dba5ed65d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " coordinator_logs.txt\n",
            " Data_Analysis_Quality_Preprocessing.ipynb\n",
            " data_analysis_report.json\n",
            " dataset_data.json\n",
            " explainability_output\n",
            " explainability_outputs\n",
            " hyperparams.json\n",
            " Notebook_5_CodeGen_Explainability.ipynb\n",
            " Part_1_Environment_Setup.ipynb\n",
            " Part_3_Model_Training_and_Evaluation.ipynb\n",
            " part3_output.json\n",
            " part4_output.json\n",
            " preprocessed_data.pt\n",
            " processed_dataset.csv\n",
            " quality_check_report.json\n",
            " selected_config_checkpoint.pkl\n",
            " Sentiment_Analysis_Model_Optimization.ipynb\n",
            " trained_traditional_ml_random_forest-like_encoder.joblib\n",
            " trained_traditional_ml_random_forest-like.joblib\n",
            " trained_traditional_ml_random_forest-like_vectorizer.joblib\n",
            "'train_traditional_ml_(random_forest-like).py'\n",
            " train_traditional_ml_random_forest-like.py\n",
            " user_feedback.csv\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/drive/MyDrive/Sentiment_Project\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_9yO7rx3kQS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Save Model Details and Generate Integration File\n",
        "# Purpose: Save model details (e.g., accuracy, hyperparameters) to a file and generate a non-.py integration file for user software.\n",
        "\n",
        "import json\n",
        "import os\n",
        "import logging\n",
        "from google.colab import drive\n",
        "import joblib\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Configure logging if not already done\n",
        "if not logging.getLogger().handlers:\n",
        "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "def save_model_details(model_path, dataset_path, output_path):\n",
        "    \"\"\"Save model details including accuracy and hyperparameters to a JSON file.\n",
        "    Args:\n",
        "        model_path (str): Path to the saved model file.\n",
        "        dataset_path (str): Path to the dataset CSV file.\n",
        "        output_path (str): Path to save the details file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load the trained model\n",
        "        model = joblib.load(model_path)\n",
        "        logger.info(f\"Loaded model from {model_path}\")\n",
        "\n",
        "        # Load the vectorizer used during training\n",
        "        vectorizer_path = model_path.replace('.joblib', '_vectorizer.joblib')\n",
        "        if not os.path.exists(vectorizer_path):\n",
        "            raise FileNotFoundError(f\"Vectorizer not found at {vectorizer_path}. Ensure Cell 3b completed successfully.\")\n",
        "        vectorizer = joblib.load(vectorizer_path)\n",
        "        logger.info(f\"Loaded vectorizer from {vectorizer_path}\")\n",
        "\n",
        "        # Load dataset\n",
        "        df = pd.read_csv(dataset_path)\n",
        "        X = vectorizer.transform(df['review'])  # Use the loaded vectorizer\n",
        "        y = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "        y_pred = model.predict(X)\n",
        "        accuracy = accuracy_score(y, y_pred)\n",
        "\n",
        "        # Load selected_config for hyperparameters\n",
        "        with open(\"/content/drive/MyDrive/Sentiment_Project/part4_output.json\", \"r\") as f:\n",
        "            selected_config = json.load(f)[\"selected_config\"]\n",
        "        hyperparams = selected_config.get(\"hyperparams\", {})\n",
        "\n",
        "        # Prepare details\n",
        "        model_details = {\n",
        "            \"model_name\": selected_config.get(\"model\", \"Traditional ML (Random Forest-like)\"),\n",
        "            \"hyperparameters\": hyperparams,\n",
        "            \"accuracy\": float(accuracy),\n",
        "            \"timestamp\": pd.Timestamp.now().isoformat(),\n",
        "            \"sample_size\": len(df)\n",
        "        }\n",
        "\n",
        "        # Save to JSON\n",
        "        with open(output_path, \"w\") as f:\n",
        "            json.dump(model_details, f, indent=2)\n",
        "        logger.info(f\"Model details saved to {output_path}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error saving model details: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def generate_code_integration_file(model_path, output_path):\n",
        "    \"\"\"Generate a non-.py integration file (e.g., .pyi or JSON) for user software integration.\n",
        "    Args:\n",
        "        model_path (str): Path to the saved model file.\n",
        "        output_path (str): Path to save the integration file (e.g., .json).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load model\n",
        "        model = joblib.load(model_path)\n",
        "\n",
        "        # Generate integration details (e.g., API-like structure)\n",
        "        integration_content = {\n",
        "            \"model_type\": \"RandomForestClassifier\",\n",
        "            \"predict_method\": {\n",
        "                \"input\": \"list of strings (text reviews)\",\n",
        "                \"output\": \"array of integers (0 for negative, 1 for positive)\",\n",
        "                \"example\": \"predict(['good review', 'bad review'])\"\n",
        "            },\n",
        "            \"load_path\": model_path,\n",
        "            \"required_libraries\": [\"joblib\", \"sklearn.ensemble\"],\n",
        "            \"version\": \"1.0\"\n",
        "        }\n",
        "\n",
        "        # Save as JSON (can be adjusted to .pyi or other formats)\n",
        "        with open(output_path, \"w\") as f:\n",
        "            json.dump(integration_content, f, indent=2)\n",
        "        logger.info(f\"Integration file saved to {output_path}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error generating integration file: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "# Run the functions\n",
        "try:\n",
        "    model_path = \"/content/drive/MyDrive/Sentiment_Project/trained_traditional_ml_random_forest-like.joblib\"\n",
        "    dataset_path = \"/content/drive/MyDrive/Sentiment_Project/processed_dataset.csv\"\n",
        "    details_path = os.path.join(\"/content/drive/MyDrive/Sentiment_Project\", \"model_details.json\")\n",
        "    integration_path = os.path.join(\"/content/drive/MyDrive/Sentiment_Project\", \"model_integration.json\")\n",
        "\n",
        "    save_model_details(model_path, dataset_path, details_path)\n",
        "    generate_code_integration_file(model_path, integration_path)\n",
        "except Exception as e:\n",
        "    logger.error(f\"Error in final processing: {str(e)}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "6eKp5VF1YxkE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c4177c0-bb5a-4353-da9b-e430c10afc60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AlTRPN-zY5vu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}